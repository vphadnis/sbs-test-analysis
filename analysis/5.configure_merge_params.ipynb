{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Merge Module Params\n",
    "\n",
    "This notebook should be used as a test for ensuring correct merge parameters before merge processing.\n",
    "Cells marked with <font color='red'>SET PARAMETERS</font> contain crucial variables that need to be set according to your specific experimental setup and data organization.\n",
    "Please review and modify these variables as needed before proceeding with the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>SET PARAMETERS</font>\n",
    "\n",
    "### Fixed parameters for merge processing\n",
    "\n",
    "- `CONFIG_FILE_PATH`: Path to a Brieflow config file used during processing. Absolute or relative to where workflows are run from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE_PATH = \"config/config.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "from lib.shared.file_utils import get_filename\n",
    "from lib.shared.configuration_utils import (\n",
    "    plot_combined_tile_grid,\n",
    "    plot_merge_example,\n",
    "    CONFIG_FILE_HEADER,\n",
    ")\n",
    "from lib.merge.hash import hash_cell_locations, initial_alignment\n",
    "from lib.merge.eval_alignment import plot_alignment_quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>SET PARAMETERS</font>\n",
    "\n",
    "### Determine merge plate-well combos\n",
    "- `MERGE_COMBO_DF_FP`: Plate used for testing configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGE_COMBO_DF_FP = \"config/merge_combo.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config file and determine root path\n",
    "with open(CONFIG_FILE_PATH, \"r\") as config_file:\n",
    "    config = yaml.safe_load(config_file)\n",
    "\n",
    "SBS_COMBO_FP = Path(config[\"preprocess\"][\"sbs_combo_fp\"])\n",
    "sbs_wildcard_combos = pd.read_csv(SBS_COMBO_FP, sep=\"\\t\")\n",
    "PHENOTYPE_COMBO_FP = Path(config[\"preprocess\"][\"phenotype_combo_fp\"])\n",
    "phenotype_wildcard_combos = pd.read_csv(PHENOTYPE_COMBO_FP, sep=\"\\t\")\n",
    "\n",
    "# Generate plate-well combinations for merge\n",
    "sbs_combos = set(zip(sbs_wildcard_combos[\"plate\"], sbs_wildcard_combos[\"well\"]))\n",
    "phenotype_combos = set(\n",
    "    zip(phenotype_wildcard_combos[\"plate\"], phenotype_wildcard_combos[\"well\"])\n",
    ")\n",
    "# Check if SBS and PHENOTYPE have the same plate-well combinations\n",
    "if sbs_combos == phenotype_combos:\n",
    "    merge_wildcard_combos = pd.DataFrame(list(sbs_combos), columns=[\"plate\", \"well\"])\n",
    "else:\n",
    "    warnings.warn(\n",
    "        \"SBS and PHENOTYPE do not have matching plate-well combinations. Merging requires identical sets.\"\n",
    "    )\n",
    "    merge_wildcard_combos = pd.DataFrame(columns=[\"plate\", \"well\"])\n",
    "\n",
    "merge_wildcard_combos.to_csv(MERGE_COMBO_DF_FP, sep=\"\\t\", index=False)\n",
    "merge_wildcard_combos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>SET PARAMETERS</font>\n",
    "\n",
    "### Parameters for testing merge module\n",
    "- `TEST_PLATE`: Plate used for testing configuration \n",
    "- `TEST_WELL`: Well identifier used for testing configuration \n",
    "\n",
    "### Parameters for metadata extraction\n",
    "- `SBS_METADATA_CYCLE`: Cycle number for extracting SBS data positions\n",
    "- `SBS_METADATA_CHANNEL`: Optional channel for SBS metadata. This is necessary in the case that multiple channel-based images were acquired, and therefore, multiple channel-based metadata files exist.\n",
    "- `PH_METADATA_CHANNEL`: Optional channel for phenotype metadata. This is necessary in the case that multiple channel-based images were acquired, and therefore, multiple channel-based metadata files exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PLATE = None\n",
    "TEST_WELL = None\n",
    "\n",
    "SBS_METADATA_CYCLE = 1\n",
    "SBS_METADATA_CHANNEL = None\n",
    "PH_METADATA_CHANNEL = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_FP = Path(config[\"all\"][\"root_fp\"])\n",
    "\n",
    "# load phenotype and SBS metadata dfs\n",
    "ph_filename_params = {\"plate\": TEST_PLATE, \"well\": TEST_WELL}\n",
    "if PH_METADATA_CHANNEL is not None:\n",
    "    ph_filename_params[\"channel\"] = PH_METADATA_CHANNEL\n",
    "\n",
    "ph_test_metadata_fp = (\n",
    "    ROOT_FP\n",
    "    / \"preprocess\"\n",
    "    / \"metadata\"\n",
    "    / \"phenotype\"\n",
    "    / get_filename(ph_filename_params, \"combined_metadata\", \"parquet\")\n",
    ")\n",
    "ph_test_metadata = pd.read_parquet(ph_test_metadata_fp)\n",
    "\n",
    "sbs_filename_params = {\"plate\": TEST_PLATE, \"well\": TEST_WELL}\n",
    "if SBS_METADATA_CHANNEL is not None:\n",
    "    sbs_filename_params[\"channel\"] = SBS_METADATA_CHANNEL\n",
    "\n",
    "sbs_test_metadata_fp = (\n",
    "    ROOT_FP\n",
    "    / \"preprocess\"\n",
    "    / \"metadata\"\n",
    "    / \"sbs\"\n",
    "    / get_filename(sbs_filename_params, \"combined_metadata\", \"parquet\")\n",
    ")\n",
    "sbs_test_metadata = pd.read_parquet(sbs_test_metadata_fp)\n",
    "sbs_test_metadata = sbs_test_metadata[sbs_test_metadata[\"cycle\"] == SBS_METADATA_CYCLE]\n",
    "\n",
    "# create plot with combined tile view\n",
    "combined_tile_grid = plot_combined_tile_grid(ph_test_metadata, sbs_test_metadata)\n",
    "combined_tile_grid.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>SET PARAMETERS</font>\n",
    "\n",
    "### Parameters for testing merge processing\n",
    "\n",
    "- `INITIAL_SITES`: Combinations of phenotype and SBS tiles used for configuring merge module parameters. Based on the combined grid above, set 6 aligned intial sites. We will load images for one of those sites, to ensure that we can visualize cell patterns (using the DAPI channel) that correspond between two tiles that will make up our initial sites. We recommend using aligned sites from across the plate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INITIAL_SITES = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive sites for phenotype and sbs\n",
    "phenotype_tiles = [site[0] for site in INITIAL_SITES]\n",
    "sbs_tiles = [site[1] for site in INITIAL_SITES]\n",
    "\n",
    "# Derive phenotype alignment hash\n",
    "phenotype_info_fp = (\n",
    "    ROOT_FP\n",
    "    / \"phenotype\"\n",
    "    / \"parquets\"\n",
    "    / get_filename(\n",
    "        {\"plate\": TEST_PLATE, \"well\": TEST_WELL}, \"phenotype_info\", \"parquet\"\n",
    "    )\n",
    ")\n",
    "phenotype_info = pd.read_parquet(phenotype_info_fp)\n",
    "phenotype_info_hash = hash_cell_locations(phenotype_info)\n",
    "\n",
    "# Derive SBS alignment hash\n",
    "sbs_info_fp = (\n",
    "    ROOT_FP\n",
    "    / \"sbs\"\n",
    "    / \"parquets\"\n",
    "    / get_filename({\"plate\": TEST_PLATE, \"well\": TEST_WELL}, \"sbs_info\", \"parquet\")\n",
    ")\n",
    "sbs_info = pd.read_parquet(sbs_info_fp)\n",
    "sbs_info_hash = hash_cell_locations(sbs_info).rename(columns={\"tile\": \"site\"})\n",
    "\n",
    "# Perform alignment for initial sites\n",
    "initial_alignment_df = initial_alignment(\n",
    "    phenotype_info_hash, sbs_info_hash, initial_sites=INITIAL_SITES\n",
    ")\n",
    "initial_alignment_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>SET PARAMETERS</font>\n",
    "\n",
    "### Visualize gating strategy based on initial alignment\n",
    "\n",
    "- `DET_RANGE`: Enforces valid magnification ratios between phenotype and genotype images.\n",
    "  - The determinant range accounts for differences in:\n",
    "    - Objective magnifications (e.g., 20X vs 10X)\n",
    "    - Camera binning settings (e.g., 2x2 vs unbinned)\n",
    "  - Calculation formula:\n",
    "    - If magnification ratio = M and binning ratio = B\n",
    "    - Total difference factor = M × B\n",
    "    - `DET_RANGE` = [0.9/(M×B)², 1.15/(M×B)²]\n",
    "  - Example:\n",
    "    - With 2× magnification difference and 2× binning difference\n",
    "    - Total difference factor = 2 × 2 = 4\n",
    "    - `DET_RANGE` = [0.9/16, 1.15/16] = [0.056, 0.072]\n",
    "  - Adjust range as needed for matching precision\n",
    "- `SCORE`: This parameter is the score of the transformation, typically 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DET_RANGE = None\n",
    "SCORE = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_alignment_quality(\n",
    "    initial_alignment_df, det_range=DET_RANGE, score=SCORE, xlim=(0, 0.1), ylim=(0, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>SET PARAMETERS</font>\n",
    "\n",
    "### Visualize cell matches based on initial alignment\n",
    "\n",
    "- `THRESHOLD`: Determines the maximum euclidean distance between a phenotype point and its matched SBS point for them to be considered a valid match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment_vec_example = initial_alignment_df[\n",
    "    (initial_alignment_df[\"tile\"] == INITIAL_SITES[0][0])\n",
    "    & (initial_alignment_df[\"site\"] == INITIAL_SITES[0][1])\n",
    "].iloc[0]\n",
    "\n",
    "plot_merge_example(\n",
    "    phenotype_info,\n",
    "    sbs_info,\n",
    "    alignment_vec_example,\n",
    "    threshold=THRESHOLD,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add merge parameters to config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add merge section\n",
    "config[\"merge\"] = {\n",
    "    \"merge_combo_fp\": MERGE_COMBO_DF_FP,\n",
    "    \"sbs_metadata_cycle\": SBS_METADATA_CYCLE,\n",
    "    \"sbs_metadata_channel\": SBS_METADATA_CHANNEL,\n",
    "    \"ph_metadata_channel\": PH_METADATA_CHANNEL,\n",
    "    \"initial_sites\": INITIAL_SITES,\n",
    "    \"det_range\": DET_RANGE,\n",
    "    \"score\": SCORE,\n",
    "    \"threshold\": THRESHOLD,\n",
    "}\n",
    "\n",
    "# Write the updated configuration back with markdown-style comments\n",
    "with open(CONFIG_FILE_PATH, \"w\") as config_file:\n",
    "    # Write the introductory markdown-stylåe comments\n",
    "    config_file.write(CONFIG_FILE_HEADER)\n",
    "\n",
    "    # Dump the updated YAML structure, keeping markdown comments for sections\n",
    "    yaml.dump(config, config_file, default_flow_style=False, sort_keys=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brieflow_main_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
