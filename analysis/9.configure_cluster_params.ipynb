{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Cluster Module Params\n",
    "\n",
    "This notebook should be used as a test for ensuring correct cluster parameters before cluster processing.\n",
    "Cells marked with <font color='red'>SET PARAMETERS</font> contain crucial variables that need to be set according to your specific experimental setup and data organization.\n",
    "Please review and modify these variables as needed before proceeding with the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>SET PARAMETERS</font>\n",
    "\n",
    "### Fixed parameters for cluster module\n",
    "\n",
    "- `CONFIG_FILE_PATH`: Path to a Brieflow config file used during processing. Absolute or relative to where workflows are run from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE_PATH = \"config/config.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning) # filter Phate warnings\n",
    "\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from lib.shared.file_utils import get_filename\n",
    "from lib.cluster.cluster_eval import plot_cell_histogram, plot_cluster_sizes\n",
    "from lib.cluster.phate_leiden_clustering import (\n",
    "    phate_leiden_pipeline,\n",
    "    plot_phate_leiden_clusters,\n",
    ")\n",
    "from lib.cluster.benchmark_clusters import (\n",
    "    evaluate_resolution,\n",
    "    run_benchmark_analysis,\n",
    ")\n",
    "from lib.cluster.scrape_benchmarks import (\n",
    "    get_uniprot_data,\n",
    "    generate_string_pair_benchmark,\n",
    "    generate_corum_group_benchmark,\n",
    "    generate_msigdb_group_benchmark,\n",
    "    filter_complexes,\n",
    ")\n",
    "from lib.shared.configuration_utils import CONFIG_FILE_HEADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config file and determine root path\n",
    "with open(CONFIG_FILE_PATH, \"r\") as config_file:\n",
    "    config = yaml.safe_load(config_file)\n",
    "    ROOT_FP = Path(config[\"all\"][\"root_fp\"])\n",
    "\n",
    "# load cell classes and channel combos\n",
    "aggregate_combo_fp = config[\"aggregate\"][\"aggregate_combo_fp\"]\n",
    "aggregate_combos = pd.read_csv(aggregate_combo_fp, sep=\"\\t\")\n",
    "\n",
    "CHANNEL_COMBOS = aggregate_combos[\"channel_combo\"].unique().tolist()\n",
    "print(f\"Channel Combos: {CHANNEL_COMBOS}\")\n",
    "\n",
    "CELL_CLASSES = list(aggregate_combos[\"cell_class\"].unique())\n",
    "print(f\"Cell classes: {CELL_CLASSES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>SET PARAMETERS</font>\n",
    "\n",
    "### Cluster preprocessing\n",
    "\n",
    "- `MIN_CELL_CUTOFFS`: Dictionary with minimum cells for each gene to be used in clusetering analysis. More cells per gene increases confidence, but some dataset types (ex mitotic) may have an inherently low number of cells for a particular perturbation. Ex `{\"mitotic\": 0, \"interphase\": 3, \"all\": 3}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_CELL_CUTOFFS = None\n",
    "\n",
    "PERTURBATION_NAME_COL = config[\"aggregate\"][\"perturbation_name_col\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell_class, min_cell_cutoff in MIN_CELL_CUTOFFS.items():\n",
    "    channel_combo = CHANNEL_COMBOS[0]\n",
    "    aggregated_data_path = ROOT_FP / \"aggregate\" / \"tsvs\" / get_filename(\n",
    "        {\"cell_class\": cell_class, \"channel_combo\": channel_combo},\n",
    "        \"aggregated\",\n",
    "        \"tsv\",\n",
    "    )\n",
    "    aggregated_data = pd.read_csv(aggregated_data_path, sep=\"\\t\")\n",
    "\n",
    "    # show cell count distribution\n",
    "    print(f\"Cell count distribution for: {cell_class}\")\n",
    "    plot_cell_histogram(aggregated_data, min_cell_cutoff, PERTURBATION_NAME_COL)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>SET PARAMETERS</font>\n",
    "\n",
    "### Benchmark Generation\n",
    "\n",
    "- `STRING_PAIR_BENCHMARK_FP`: Path to save and access STRING pair benchmark.\n",
    "- `CORUM_GROUP_BENCHMARK_FP`: Path to save and access CORUM group benchmark.\n",
    "- `KEGG_GROUP_BENCHMARK_FP`: Path to save and access KEGG group benchmark.\n",
    "\n",
    "**Note**: We use the following benchmark schemas:\n",
    "- Pair Bechmark: `gene_name` column for gene matching with a cluster gene (or does not exist in cluster genes); `pair` column with a pair ID. Used to benchmark known pair relationships in generated cluster.\n",
    "- Group Bechmark: `gene_name` column for gene matching with a cluster gene (or does not exist in cluster genes); `group` column with a group ID. Used to benchmark known group relationships in generated cluster, where a group represents genes involved in a pathway, protein complex, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNIPROT_DATA_FP = \"config/benchmark_clusters/uniprot_data.tsv\"\n",
    "STRING_PAIR_BENCHMARK_FP = \"config/benchmark_clusters/string_pair_benchmark.tsv\"\n",
    "CORUM_GROUP_BENCHMARK_FP = \"config/benchmark_clusters/corum_group_benchmark.tsv\"\n",
    "KEGG_GROUP_BENCHMARK_FP = \"config/benchmark_clusters/kegg_group_benchmark.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(STRING_PAIR_BENCHMARK_FP).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "uniprot_data = get_uniprot_data()\n",
    "uniprot_data.to_csv(UNIPROT_DATA_FP, sep=\"\\t\", index=False)\n",
    "uniprot_data = pd.read_csv(UNIPROT_DATA_FP, sep=\"\\t\")\n",
    "display(uniprot_data)\n",
    "\n",
    "string_pair_benchmark = generate_string_pair_benchmark(aggregated_data, uniprot_data, \"gene_symbol_0\")\n",
    "string_pair_benchmark.to_csv(STRING_PAIR_BENCHMARK_FP, sep=\"\\t\", index=False)\n",
    "string_pair_benchmark = pd.read_csv(STRING_PAIR_BENCHMARK_FP, sep=\"\\t\")\n",
    "display(string_pair_benchmark)\n",
    "\n",
    "corum_group_benchmark = generate_corum_group_benchmark()\n",
    "corum_group_benchmark.to_csv(CORUM_GROUP_BENCHMARK_FP, sep=\"\\t\", index=False)\n",
    "corum_group_benchmark = pd.read_csv(CORUM_GROUP_BENCHMARK_FP, sep=\"\\t\")\n",
    "display(corum_group_benchmark)\n",
    "\n",
    "kegg_group_benchmark = generate_msigdb_group_benchmark()\n",
    "kegg_group_benchmark.to_csv(KEGG_GROUP_BENCHMARK_FP, sep=\"\\t\", index=False)\n",
    "kegg_group_benchmark = pd.read_csv(KEGG_GROUP_BENCHMARK_FP, sep=\"\\t\")\n",
    "display(kegg_group_benchmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>SET PARAMETERS</font>\n",
    "\n",
    "### Test Dataset\n",
    "\n",
    "- `TEST_CELL_CLASS`: Cell class to test clustering on. Usually `all` or cell class of interest.\n",
    "- `TEST_CHANNEL_COMBO`: Cell class to test clustering on. Usually `all` or cell class of interest.\n",
    "\n",
    "### Phate/Leiden Clustering\n",
    "\n",
    "- `PHATE_DISTANCE_METRIC`: Distance metric used by phate during dimensionality reduction. Can be `euclidean` or `cosine`, `cosine` is recommended. Check out this [blog post](https://cmry.github.io/notes/euclidean-v-cosine) for more insight on how to choose a clustering metric.\n",
    "- `TEST_LEIDEN_RESOLUTIONS`: Resolutions for Leiden clustering. Higher means more clusters (and therefore less genes per cluster). Should be a list of numbers. We recommend `[0.1, 1, 5, 7, 9, 11, 13, 15, 20, 100]`. \n",
    "\n",
    "**Notes**: \n",
    "- Every resolution takes about 1 minute to generate a cluster for.\n",
    "- `evaluate_resolution` automatically filters benchmarks to only include genes that we have in the perturbations column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_CELL_CLASS = None\n",
    "TEST_CHANNEL_COMBO = None\n",
    "\n",
    "PHATE_DISTANCE_METRIC = None\n",
    "TEST_LEIDEN_RESOLUTIONS = None\n",
    "\n",
    "CONTROL_KEY = config[\"aggregate\"][\"control_key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_data_path = ROOT_FP / \"aggregate\" / \"tsvs\" / get_filename(\n",
    "    {\"cell_class\": TEST_CELL_CLASS, \"channel_combo\": TEST_CHANNEL_COMBO},\n",
    "    \"aggregated\",\n",
    "    \"tsv\",\n",
    ")\n",
    "aggregated_data = pd.read_csv(aggregated_data_path, sep=\"\\t\")\n",
    "\n",
    "aggregated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_data_path = ROOT_FP / \"aggregate\" / \"tsvs\" / get_filename(\n",
    "    {\"cell_class\": TEST_CELL_CLASS, \"channel_combo\": TEST_CHANNEL_COMBO},\n",
    "    \"aggregated\",\n",
    "    \"tsv\",\n",
    ")\n",
    "aggregated_data = pd.read_csv(aggregated_data_path, sep=\"\\t\")\n",
    "\n",
    "# create baseline data by shuffling columns independently\n",
    "shuffled_aggregated_data = aggregated_data.copy()\n",
    "feature_start_idx = shuffled_aggregated_data.columns.get_loc(\"PC_0\")\n",
    "feature_cols = shuffled_aggregated_data.columns[feature_start_idx:]\n",
    "for col in feature_cols:\n",
    "    shuffled_aggregated_data[col] = np.random.permutation(\n",
    "        shuffled_aggregated_data[col].values\n",
    "    )\n",
    "\n",
    "# Run the benchmark analysis with the CORUM clusters\n",
    "group_benchmarks = {\n",
    "    \"CORUM\": corum_group_benchmark,\n",
    "}\n",
    "\n",
    "# Run the resolution thresholding analysis\n",
    "results_df, thresholding_fig = evaluate_resolution(\n",
    "    aggregated_data,\n",
    "    PHATE_DISTANCE_METRIC,\n",
    "    TEST_LEIDEN_RESOLUTIONS,\n",
    "    group_benchmarks,\n",
    "    PERTURBATION_NAME_COL,\n",
    "    CONTROL_KEY\n",
    ")\n",
    "\n",
    "# Display the figure \n",
    "plt.figure(thresholding_fig.number)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>SET PARAMETERS</font>\n",
    "\n",
    "### Phate/Leiden Clustering\n",
    "\n",
    "- `CLUSTER_COMBO_FP`: Location of cluster combinations dataframe.\n",
    "- `FINAL_LEIDEN_RESOLUTIONS`: Final list of resolutions for Leiden clustering. The snakmake cluster module will create and benchmark clusters for each of these resolutions. For the rest of the cluster testing in this notebook, we will show one example of this cluster generation and benchmarking (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_COMBO_FP = \"config/cluster_combo.tsv\"\n",
    "FINAL_LEIDEN_RESOLUTIONS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load aggregate wildcard combos\n",
    "AGGREGATE_COMBO_FP = Path(config[\"aggregate\"][\"aggregate_combo_fp\"])\n",
    "aggregate_wildcard_combos = pd.read_csv(AGGREGATE_COMBO_FP, sep=\"\\t\")\n",
    "\n",
    "# Generate cluster wildcard combos\n",
    "cluster_wildcard_combos = aggregate_wildcard_combos[[\"cell_class\", \"channel_combo\"]].drop_duplicates()\n",
    "cluster_wildcard_combos[\"leiden_resolution\"] = [FINAL_LEIDEN_RESOLUTIONS] * len(cluster_wildcard_combos)\n",
    "cluster_wildcard_combos = cluster_wildcard_combos.explode(\"leiden_resolution\", ignore_index=True)\n",
    "\n",
    "# Save aggregate wildcard combos\n",
    "cluster_wildcard_combos.to_csv(CLUSTER_COMBO_FP, sep=\"\\t\", index=False)\n",
    "\n",
    "print(\"Cluster wildcard combos:\")\n",
    "cluster_wildcard_combos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>SET PARAMETERS</font>\n",
    "\n",
    "### Cluster Generation/Benchmarking Test\n",
    "\n",
    "- `TEST_LEIDEN_RESOLUTION`: Resolution for testing Leiden cluster creation and evaluation within this notebook. Each leiden resolution listed in `LEIDEN_RESOLUTIONS` above will be used during snakemake run to generate separate clusterings (see above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_LEIDEN_RESOLUTION = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phate_leiden_clustering = phate_leiden_pipeline(\n",
    "    aggregated_data,\n",
    "    TEST_LEIDEN_RESOLUTION,\n",
    "    PHATE_DISTANCE_METRIC,\n",
    ")\n",
    "uniprot_data['gene_name'] = uniprot_data['gene_names'].str.split().str[0]\n",
    "uniprot_data = uniprot_data.drop_duplicates('gene_name', keep='first')\n",
    "uniprot_subset = uniprot_data[['gene_name', 'entry', 'function', 'link']].rename(\n",
    "    columns={\n",
    "        'entry': 'uniprot_entry',\n",
    "        'function': 'uniprot_function',\n",
    "        'link': 'uniprot_link'\n",
    "    }\n",
    ")\n",
    "phate_leiden_clustering = phate_leiden_clustering.merge(\n",
    "    uniprot_subset,\n",
    "    how='left',\n",
    "    left_on='gene_symbol_0',\n",
    "    right_on='gene_name'\n",
    ").drop(columns='gene_name')\n",
    "display(phate_leiden_clustering)\n",
    "\n",
    "cluster_size_fig = plot_cluster_sizes(phate_leiden_clustering)\n",
    "plt.show()\n",
    "\n",
    "clusters_fig = plot_phate_leiden_clusters(\n",
    "    phate_leiden_clustering, PERTURBATION_NAME_COL, CONTROL_KEY\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phate_leiden_clustering_shuffled = phate_leiden_pipeline(\n",
    "    shuffled_aggregated_data,\n",
    "    TEST_LEIDEN_RESOLUTION,\n",
    "    PHATE_DISTANCE_METRIC,\n",
    ")\n",
    "\n",
    "cluster_datasets = {\n",
    "    \"Real\": phate_leiden_clustering,\n",
    "    \"Shuffled\": phate_leiden_clustering_shuffled,\n",
    "}\n",
    "\n",
    "pair_recall_benchmarks = {\n",
    "    \"STRING\": string_pair_benchmark,\n",
    "}\n",
    "\n",
    "group_enrichment_benchmarks = {\n",
    "    \"CORUM\": filter_complexes(corum_group_benchmark, phate_leiden_clustering, perturbation_col_name=PERTURBATION_NAME_COL, control_key=CONTROL_KEY),\n",
    "    \"KEGG\": filter_complexes(kegg_group_benchmark, phate_leiden_clustering, perturbation_col_name=PERTURBATION_NAME_COL, control_key=CONTROL_KEY),\n",
    "}\n",
    "\n",
    "integrated_results, combined_tables, global_metrics, pie_charts, cluster_enrichment_plots = run_benchmark_analysis(\n",
    "    cluster_datasets,\n",
    "    string_pair_benchmark,\n",
    "    corum_group_benchmark,\n",
    "    kegg_group_benchmark,\n",
    "    PERTURBATION_NAME_COL,\n",
    "    CONTROL_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add cluster parameters to config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cluster section\n",
    "config[\"cluster\"] = {\n",
    "    \"min_cell_cutoffs\": MIN_CELL_CUTOFFS,\n",
    "    \"leiden_resolutions\": FINAL_LEIDEN_RESOLUTIONS,\n",
    "    \"phate_distance_metric\": PHATE_DISTANCE_METRIC,\n",
    "    \"cluster_combo_fp\": CLUSTER_COMBO_FP,\n",
    "    \"uniprot_data_fp\": UNIPROT_DATA_FP,\n",
    "    \"string_pair_benchmark_fp\": STRING_PAIR_BENCHMARK_FP,\n",
    "    \"corum_group_benchmark_fp\": CORUM_GROUP_BENCHMARK_FP,\n",
    "    \"kegg_group_benchmark_fp\": KEGG_GROUP_BENCHMARK_FP,\n",
    "}\n",
    "\n",
    "# Write the updated configuration\n",
    "with open(CONFIG_FILE_PATH, \"w\") as config_file:\n",
    "    # Write the introductory comments\n",
    "    config_file.write(CONFIG_FILE_HEADER)\n",
    "\n",
    "    # Dump the updated YAML structure, keeping markdown comments for sections\n",
    "    yaml.dump(config, config_file, default_flow_style=False, sort_keys=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brieflow_main_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
